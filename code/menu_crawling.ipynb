{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a16672f",
   "metadata": {},
   "source": [
    "# 상록원 메뉴 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e3826",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b392b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from datetime import datetime\n",
    "import re                                           \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f026bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스케줄러 시작: 매주 일요일 00:00에 crawl() 실행\n"
     ]
    }
   ],
   "source": [
    "def crawl():\n",
    "    print(f\"[{datetime.now()}] 크롤링 시작\")\n",
    "    \n",
    "\n",
    "    BASE_URL  = \"https://dgucoop.dongguk.edu/store/store.php\"\n",
    "\n",
    "    def fetch_week_page(offset):\n",
    "        params = {\"w\": 4, \"l\": 2, \"j\": offset}\n",
    "        resp = requests.get(BASE_URL, params=params)\n",
    "        resp.encoding = 'euc-kr'\n",
    "        return resp.text\n",
    "\n",
    "    def clean_menu(raw):\n",
    "        \"\"\"메뉴 텍스트에서 불필요한 부분(괄호·가격·시간 등) 제거\"\"\"\n",
    "        # 1) 괄호 안 내용 제거\n",
    "        txt = re.sub(r'\\(.*?\\)', '', raw)\n",
    "        # 2) 줄바꿈→공백\n",
    "        txt = txt.replace('\\n', ' ')\n",
    "        # 3) 가격 패턴 제거\n",
    "        txt = re.sub(r'￦\\s*[0-9,]+|[0-9]+원', '', txt)\n",
    "        # 4) 시간/기간 제거\n",
    "        txt = re.sub(r'\\d{1,2}:\\d{2}(?:~\\d{1,2}:\\d{2})?', '', txt)\n",
    "        # 5) 프로모션 별표 제거\n",
    "        txt = re.sub(r'\\*{2,}[^*]*', '', txt)\n",
    "        # 6) 한글·공백 외 모두 제거\n",
    "        txt = re.sub(r'[^가-힣\\s&]', ' ', txt)\n",
    "        # 7) 중복 공백 정리\n",
    "        return re.sub(r'\\s+', ' ', txt).strip()\n",
    "\n",
    "    def clean_menu2(text):\n",
    "        UNWANTED_WORDS = {\n",
    "            '삼겹', '돼지', '오스트리아산', '닭', '브라질산',\n",
    "            '소', '미국산', '스팸', '외국산', '돈가스',\n",
    "            '낙지', '베트남산', '쌀', '배추김치', '배추', '고춧가루'\n",
    "        }\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        # 기존 정리 로직...\n",
    "        text = re.sub(r'\\(.*?\\)', '', text)\n",
    "        text = text.replace('\\n', ' ')\n",
    "        # text = re.sub(r'￦\\s*[0-9,]+|[0-9]+원', '', text)\n",
    "        text = re.sub(r'\\d{1,2}:\\d{2}(?:~\\d{1,2}:\\d{2})?(?:/?\\s*\\d{1,2}:\\d{2}(?:~\\d{1,2}:\\d{2})?)?', '', text)\n",
    "        text = re.sub(r'\\*{2,}[^*]*', '', text)\n",
    "        text = re.sub(r'[^가-힣\\s&]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        for kw in ['전기실', '변압기', '고장', '운영중단', '분식당', '국내산']:\n",
    "            if kw in text:\n",
    "                return text.replace(f'{kw}', '')\n",
    "        # 여기서 단어별로 분리한 뒤, UNWANTED_WORDS 에 딱 일치하는 토큰만 제거\n",
    "        tokens = text.split()\n",
    "        for tok in UNWANTED_WORDS:\n",
    "            if tok in tokens:\n",
    "                return text.replace(f'{tok}', '')\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    def extract_headers(table):\n",
    "        \"\"\"한 테이블의 요일+날짜 헤더( span태그 ) 리스트로 반환\"\"\"\n",
    "        spans = table.select('tr.mft td span')\n",
    "        return [span.get_text(strip=True) for span in spans]\n",
    "\n",
    "    def parse_menu(html):\n",
    "        soup    = BeautifulSoup(html, 'html.parser')\n",
    "        records = []\n",
    "        # 모든 메뉴 테이블 순회\n",
    "        for table in soup.find_all('table', attrs={'bgcolor':'#CDD6B5'}):\n",
    "            # 1) 헤더(요일+날짜) 추출\n",
    "            headers = [span.get_text(strip=True) for span in table.select('tr.mft td span')]\n",
    "            # 2) 실제 데이터는 세 번째 <tr> 부터\n",
    "            rows = table.find_all('tr')[2:]\n",
    "            current_restaurant = None\n",
    "            current_category   = None\n",
    "\n",
    "            for tr in rows:\n",
    "                # — 식당(코너)명 만나면 갱신 —\n",
    "                rst_td = tr.find('td', class_='menu_st')\n",
    "                if rst_td:\n",
    "                    current_restaurant = rst_td.get_text(strip=True)\n",
    "                    current_category   = None\n",
    "                    continue\n",
    "\n",
    "                tds = tr.find_all('td')\n",
    "                if not tds:\n",
    "                    continue\n",
    "\n",
    "                first = tds[0]\n",
    "                # — 1) 일반 카테고리+중식 행 (rowspan=2, colspan 없음) —\n",
    "                if first.has_attr('rowspan') and not first.has_attr('colspan'):\n",
    "                    current_category = first.get_text(strip=True)\n",
    "                    meal_type        = tds[1].get_text(strip=True)  # '중식'\n",
    "                    start_idx        = 2\n",
    "\n",
    "                # — 2) 특수 메뉴 블럭 (rowspan=7, colspan=2인 “메뉴”, “누리밥상” 등) —\n",
    "                elif first.has_attr('rowspan') and first.has_attr('colspan'):\n",
    "                    current_category = first.get_text(strip=True)\n",
    "                    # colspan=2 이므로 tds[1]이 실제 첫날(일요일) 셀\n",
    "                    # tds[1]이 비어 있으면, tds[2]가 첫날 메뉴일 수도 있으니 상황에 맞게 조정\n",
    "                    meal_type = ''  # 필요시 비워두거나 '중식'으로 디폴트\n",
    "                    start_idx = 1\n",
    "\n",
    "                # — 3) 석식 행 (class=\"mft\"만 있고 rowspan 없음) —\n",
    "                elif 'mft' in first.get('class', []) and not first.has_attr('rowspan'):\n",
    "                    meal_type = first.get_text(strip=True)  # '석식'\n",
    "                    start_idx = 1\n",
    "\n",
    "                else:\n",
    "                    # 기타 불필요한 행(빈 행 등) 건너뛰기\n",
    "                    continue\n",
    "\n",
    "                # — 4) start_idx 에 맞춰 헤더와 메뉴 셀 매핑 —\n",
    "                menu_cells = tds[start_idx:]\n",
    "                for idx, cell in enumerate(menu_cells):\n",
    "                    raw  = cell.get_text(' ', strip=True)\n",
    "                    menu = clean_menu(raw)\n",
    "                    if not menu:\n",
    "                        continue\n",
    "                    records.append({\n",
    "                        \"restaurant\": current_restaurant,\n",
    "                        \"category\":   current_category,\n",
    "                        \"meal\":       meal_type,\n",
    "                        \"header\":     headers[idx],  # headers 길이와 menu_cells 길이가 일치\n",
    "                        \"menu\":       menu\n",
    "                    })\n",
    "                    \n",
    "        df = pd.DataFrame(records)\n",
    "        \n",
    "        pattern = r'^([월화수목금토일])\\s*(\\d{1,2}월\\s*\\d{1,2}일)$'\n",
    "        df[['week','date']] = df['header'].str.extract(pattern)\n",
    "        df['menu_clean'] = df['menu'].apply(clean_menu2)\n",
    "        df.drop(['header', 'menu'], axis=1, inplace=True)\n",
    "        df['restaurant'][df['restaurant'].isna()] = '상록원3층식당'\n",
    "        df[6:11]['category'].replace('석식', '집밥', inplace=True)\n",
    "        df[6:11]['meal'].replace('', '석식', inplace=True)\n",
    "        df.set_index('date', inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def collect_since(start_date):\n",
    "        offset    = 0\n",
    "        all_weeks = []\n",
    "\n",
    "        while True:\n",
    "            html = fetch_week_page(offset)\n",
    "            df   = parse_menu(html)\n",
    "\n",
    "            # — 인덱스(\"05월 18일\")에서 월·일 추출 —\n",
    "            idx = df.index.to_series().astype(str)\n",
    "            m_d = idx.str.extract(r'(\\d{1,2})월\\s*(\\d{1,2})일')\n",
    "            df['월'] = m_d[0].astype(int)\n",
    "            df['일'] = m_d[1].astype(int)\n",
    "\n",
    "            # — datetime 컬럼 생성 —\n",
    "            df['date_dt'] = pd.to_datetime({\n",
    "                'year':  start_date.year,\n",
    "                'month': df['월'],\n",
    "                'day':   df['일']\n",
    "            })\n",
    "\n",
    "            # 3월 1일 이전이면 종료\n",
    "            if df['date_dt'].max().date() < start_date:\n",
    "                break\n",
    "\n",
    "            all_weeks.append(df)\n",
    "            offset -= 1\n",
    "\n",
    "        # 합치고, 3월 1일 이후만 필터\n",
    "        full = pd.concat(all_weeks, ignore_index=False)\n",
    "        return full[ full['date_dt'].dt.date >= start_date ]\n",
    "    \n",
    "    START = datetime.date(2025, 3, 1)\n",
    "    menu_df = collect_since(START)\n",
    "    result = menu_df[[\n",
    "        'restaurant', 'category', 'meal', 'week', 'menu_clean'\n",
    "    ]]\n",
    "    result.to_csv('../data/DGU_menu_final.csv', encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"[{datetime.now()}] 크롤링 완료\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scheduler = BlockingScheduler(timezone=\"Asia/Seoul\")\n",
    "\n",
    "    # 매주 일요일 00:00에 실행\n",
    "    scheduler.add_job(\n",
    "        crawl,\n",
    "        trigger='cron',\n",
    "        day_of_week='sun',\n",
    "        hour=0,\n",
    "        minute=0,\n",
    "        id='weekly_menu_crawl'\n",
    "    )\n",
    "\n",
    "    print(\"스케줄러 시작: 매주 일요일 00:00에 crawl() 실행\")\n",
    "    try:\n",
    "        scheduler.start()\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print(\"스케줄러 종료\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511733b",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
